
@book{thiruvathukal_low-power_2022,
	title = {Low-{Power} {Computer} {Vision}: {Improve} the {Efficiency} of {Artificial} {Intelligence}},
	isbn = {978-0-367-74470-0},
	url = {https://ecommons.luc.edu/cs_facpubs/281/},
	abstract = {Energy efficiency is critical for running computer vision on battery-powered systems, such as mobile phones or UAVs (unmanned aerial vehicles, or drones). This book collects the methods that have won the annual IEEE Low-Power Computer Vision Challenges since 2015. The winners share their solutions and provide insight on how to improve the efficiency of machine learning systems.},
	publisher = {Chapman and Hall/CRC Press},
	author = {Thiruvathukal, George K. and Lu, Yung-Hsiang and Kim, Jaeyoun and Chen, Yiran and Chen, Bo},
	year = {2022},
}

@book{carver_software_2017,
	title = {Software {Engineering} for {Science}},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	isbn = {978-1-4987-4385-3},
	url = {https://ecommons.luc.edu/cs_facpubs/128/},
	abstract = {Software Engineering for Science provides an in-depth collection of peer-reviewed chapters that describe with applying software engineering practices to the development of scientifi software. It provides a better understanding of how software engineering is and should be practiced, and which software engineering practices are effective for scientific software. The book starts with a detailed overview of the Scientific Software Lifecycle, and a general overview of the scientific software development process. It highlights key issues commonly arising during scientific software development, as well as solutions to these problems. The second part of the book provides examples of the use of testing in scientific software development, including key issues and challenges.},
	publisher = {Taylor \& Francis/CRC Press},
	author = {Carver, Jeffrey and Hong, Neil P. Chue and Thiruvathukal, George K.},
	year = {2017},
}

@book{jones_codename_2012,
	title = {Codename {Revolution}: {The} {Nintendo} {WII} {Platform} ({Platform} {Studies})},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	isbn = {978-0-262-01680-3},
	shorttitle = {Codename {Revolution}},
	url = {https://mitpress.mit.edu/9780262016803/codename-revolution/},
	abstract = {Nintendo's hugely popular and influential video game console system considered as technological device and social phenomenon. The Nintendo Wii, introduced in 2006, helped usher in a moment of retro-reinvention in video game play. This hugely popular console system, codenamed Revolution during development, signaled a turn away from fully immersive, time-consuming MMORPGs or forty-hour FPS games and back toward family fun in the living room. Players using the wireless motion-sensitive controller (the Wii Remote, or “Wiimote”) play with their whole bodies, waving, swinging, swaying. The mimetic interface shifts attention from what's on the screen to what's happening in physical space. This book describes the Wii's impact in technological, social, and cultural terms, examining the Wii as a system of interrelated hardware and software that was consciously designed to promote social play in physical space. Each chapter of Codename Revolution focuses on a major component of the Wii as a platform: the console itself, designed to be low-powered and nimble; the iconic Wii Remote; Wii Fit Plus, and its controller, the Wii Balance Board; the Wii Channels interface and Nintendo's distribution system; and the Wii as a social platform that not only affords multiplayer options but also encourages social interaction in shared physical space. Finally, the authors connect the Wii's revolution in mimetic interface gaming—which eventually led to the release of Sony's Move and Microsoft's Kinect—to some of the economic and technological conditions that influence the possibility of making something new in this arena of computing and culture.},
	publisher = {MIT Press},
	author = {Jones, Steven E. and Thiruvathukal, George K.},
	year = {2012},
}

@incollection{kaylor_restfs_2011,
	title = {{RestFS}: {The} {Filesystem} as a {Connector} {Abstraction} for {Flexible} {Resource} and {Service} {Composition}},
	isbn = {978-1-4398-5641-3},
	booktitle = {Cloud {Computing}: {Methodology}, {System}, and {Applications}},
	publisher = {CRC Press},
	author = {Kaylor, Joseph P. and Läufer, Konstantin and Thiruvathukal, George K.},
	editor = {Wang, Lizhe and Ranjan, Rajiv and Chen, Jinjun and Benatallah, Boualem},
	year = {2011},
}

@inproceedings{tung_irrelevant_2022,
	title = {Irrelevant {Pixels} are {Everywhere}: {Find} and {Exclude} {Them} for {More} {Efficient} {Computer} {Vision}},
	url = {https://ecommons.luc.edu/cs_facpubs/293/},
	doi = {10.1109/AICAS54282.2022.9870012},
	booktitle = {2022 {IEEE} 4th {International} {Conference} on {Artificial} {Intelligence} {Circuits} and {Systems} ({AICAS})},
	author = {Tung, Caleb and Goel, Abhinav and Hu, Xiao and Eliopoulos, Nick and Amobi, Emmanuel S. and Thiruvathukal, George K. and Chaudhary, Vipin and Lu, Yung-Hsiang},
	year = {2022},
	pages = {340--343},
}

@inproceedings{yang_are_2022,
	title = {Are {You} {Really} {Muted}?: {A} {Privacy} {Analysis} of {Mute} {Buttons} in {Video} {Conferencing} {Apps}},
	url = {https://arxiv.org/abs/2204.06128},
	doi = {10.48550/ARXIV.2204.06128},
	booktitle = {Proceedings of 22nd {Privacy} {Enhancing} {Technologies} {Symposium} ({PETS} 2022)},
	author = {Yang, Yucheng and West, Jack and Thiruvathukal, George K. and Klingensmith, Neil and Fawaz, Kassem},
	year = {2022},
}

@inproceedings{goel_directed_2022,
	address = {New York, NY, USA},
	series = {{ISLPED} '22},
	title = {Directed {Acyclic} {Graph}-{Based} {Neural} {Networks} for {Tunable} {Low}-{Power} {Computer} {Vision}},
	isbn = {978-1-4503-9354-6},
	url = {https://doi.org/10.1145/3531437.3539723},
	doi = {10.1145/3531437.3539723},
	abstract = {Processing visual data on mobile devices has many applications, e.g., emergency response and tracking. State-of-the-art computer vision techniques rely on large Deep Neural Networks (DNNs) that are usually too power-hungry to be deployed on resource-constrained edge devices. Many techniques improve DNN efficiency of DNNs by compromising accuracy. However, the accuracy and efficiency of these techniques cannot be adapted for diverse edge applications with different hardware constraints and accuracy requirements. This paper demonstrates that a recent, efficient tree-based DNN architecture, called the hierarchical DNN, can be converted into a Directed Acyclic Graph-based (DAG) architecture to provide tunable accuracy-efficiency tradeoff options. We propose a systematic method that identifies the connections that must be added to convert the tree to a DAG to improve accuracy. We conduct experiments on popular edge devices and show that increasing the connectivity of the DAG improves the accuracy to within 1\% of the existing high accuracy techniques. Our approach requires 93\% less memory, 43\% less energy, and 49\% fewer operations than the high accuracy techniques, thus providing more accuracy-efficiency configurations.},
	booktitle = {Proceedings of the {ACM}/{IEEE} {International} {Symposium} on {Low} {Power} {Electronics} and {Design}},
	publisher = {Association for Computing Machinery},
	author = {Goel, Abhinav and Tung, Caleb and Eliopoulos, Nick and Hu, Xiao and Thiruvathukal, George K. and Davis, James C. and Lu, Yung-Hsiang},
	year = {2022},
	note = {event-place: Boston, MA, USA},
}

@inproceedings{goel_efficient_2022,
	title = {Efficient {Computer} {Vision} on {Edge} {Devices} with {Pipeline}-{Parallel} {Hierarchical} {Neural} {Networks}},
	url = {https://ecommons.luc.edu/cs_facpubs/276/},
	doi = {TBD},
	abstract = {Computer vision on low-power edge devices enables applications including search-and-rescue and security. State-of-the-art computer vision algorithms, such as Deep Neural Networks (DNNs), are too large for inference on low-power edge devices. To improve efficiency, some existing approaches parallelize DNN inference across multiple edge devices. However, these techniques introduce significant communication and synchronization overheads or are unable to balance workloads across devices. This paper demonstrates that the hierarchical DNN architecture is well suited for parallel processing on multiple edge devices. We design a novel method that creates a parallel inference pipeline for computer vision problems that use hierarchical DNNs. The method balances loads across the collaborating devices and reduces communication costs to facilitate the processing of multiple video frames simultaneously with higher throughput. Our experiments consider a representative computer vision problem where image recognition is performed on each video frame, running on multiple Raspberry Pi 4Bs. With four collaborating low-power edge devices, our approach achieves 3.21X higher throughput, 68\% less energy consumption per device per frame, and 58\% decrease in memory when compared with existing single-device hierarchical DNNs.},
	booktitle = {27th {Asia} and {South} {Pacific} {Design} {Automation} {Conference} ({ASP}-{DAC})},
	author = {Goel, Abhinav and Tung, Caleb and Hu, Xiao and Thiruvathukal, George K. and Davis, James C. and Lu, Yung-Hsiang},
	year = {2022},
}

@inproceedings{jiang_empirical_2022,
	address = {New York, NY, USA},
	series = {{SCORED}'22},
	title = {An {Empirical} {Study} of {Artifacts} and {Security} {Risks} in the {Pre}-{Trained} {Model} {Supply} {Chain}},
	isbn = {978-1-4503-9885-5},
	url = {https://doi.org/10.1145/3560835.3564547},
	doi = {10.1145/3560835.3564547},
	abstract = {Deep neural networks achieve state-of-the-art performance on many tasks, but require increasingly complex architectures and costly training procedures. Engineers can reduce costs by reusing a pre-trained model (PTM) and fine-tuning it for their own tasks. To facilitate software reuse, engineers collaborate around model hubs, collections of PTMs and datasets organized by problem domain. Although model hubs are now comparable in popularity and size to other software ecosystems, the associated PTM supply chain has not yet been examined from a software engineering perspective. We present an empirical study of artifacts and security features in 8 model hubs. We indicate the potential threat models and show that the existing defenses are insufficient for ensuring the security of PTMs. We compare PTM and traditional supply chains, and propose directions for further measurements and tools to increase the reliability of the PTM supply chain.},
	booktitle = {Proceedings of the 2022 {ACM} {Workshop} on {Software} {Supply} {Chain} {Offensive} {Research} and {Ecosystem} {Defenses}},
	publisher = {Association for Computing Machinery},
	author = {Jiang, Wenxin and Synovic, Nicholas and Sethi, Rohan and Indarapu, Aryan and Hyatt, Matt and Schorlemmer, Taylor R. and Thiruvathukal, George K. and Davis, James C.},
	year = {2022},
	note = {event-place: Los Angeles, CA, USA},
	keywords = {machine learning, empirical software engineering, deep neural networks, model hubs, software reuse, software supply chain},
	pages = {105--114},
}

@inproceedings{west_moonshine_2021,
	address = {New York, NY, USA},
	title = {Moonshine: {An} {Online} {Randomness} {Distiller} for {Zero}-{Involvement} {Authentication}},
	url = {https://ecommons.luc.edu/cs_facpubs/270/},
	doi = {TBD},
	abstract = {Context-based authentication is a method for transparently validating another device's legitimacy to join a network based on location. Devices can pair with one another by continuously harvesting environmental noise to generate a random key with no user involvement. However, there are gaps in our understanding of the theoretical limitations of environmental noise harvesting, making it difficult for researchers to build efficient algorithms for sampling environmental noise and distilling keys from that noise. This work explores the information-theoretic capacity of context-based authentication mechanisms to generate random bit strings from environmental noise sources with known properties. Using only mild assumptions about the source process's characteristics, we demonstrate that commonly-used bit extraction algorithms extract only about 10\% of the available randomness from a source noise process. We present an efficient algorithm to improve the quality of keys generated by context-based methods and evaluate it on real key extraction hardware. Moonshine is a randomness distiller which is more efficient at extracting bits from an environmental entropy source than existing methods. Our techniques nearly double the quality of keys as measured by the NIST test suite, producing keys that can be used in real-world authentication scenarios.},
	booktitle = {Information {Processing} in {Sensor} {Networks} 2021 ({IPSN} 2021)},
	publisher = {Association for Computing Machinery},
	author = {West, Jack and Lee, Kyuin and Banerjee, Suman and Kim, Younghyun and Thiruvathukal, George K. and Klingensmith, Neil},
	year = {2021},
}

@inproceedings{abegaz_addressing_2020,
	address = {New York, NY, USA},
	series = {{AutomotiveUI} '20},
	title = {Addressing {Rogue} {Vehicles} by {Integrating} {Computer} {Vision}, {Activity} {Monitoring}, and {Contextual} {Information}},
	isbn = {978-1-4503-8066-9},
	url = {https://ecommons.luc.edu/cs_facpubs/266/},
	doi = {10.1145/3409251.3411724},
	abstract = {In this paper, we address the detection of rogue autonomous vehicles using an integrated approach involving computer vision, activity monitoring and contextual information. The proposed approach can be used to detect rogue autonomous vehicles using sensors installed on observer vehicles that are used to monitor and identify the behavior of other autonomous vehicles operating on the road. The safe braking distance and the safe following time are computed to identify if an autonomous vehicle is behaving properly. Our preliminary results show that there is a wide variation in both the safe following time and the safe braking distance recorded using three autonomous vehicles in a test-bed. These initial results show significant progress for the future efforts to coordinate the operation of autonomous, semi-autonomous and non-autonomous vehicles.},
	booktitle = {12th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Abegaz, Brook and Chan-Tin, Eric and Klingensmith, Neil and Thiruvathukal, George K.},
	year = {2020},
	note = {event-place: Virtual Event, DC, USA},
	pages = {62--64},
}

@inproceedings{dematties_towards_2020,
	title = {Towards {High}-{End} {Scalability} on {Biologically}-{Inspired} {Computational} {ModelsAuthors}},
	url = {https://ecommons.luc.edu/cs_facpubs/242/},
	abstract = {The interdisciplinary field of neuroscience has made significantprogress in recent decades, providing the scientific community in gen-eral with a new level of understanding on how the brain works beyondthe store-and-fire model found in traditional neural networks. Mean-while, Machine Learning (ML) based on established models has seena surge of interest in the High Performance Computing (HPC) com-munity, especially through the use of high-end accelerators, such asGraphical Processing Units (GPUs), including HPC clusters of same.In our work, we are motivated to exploit these high-performance com-puting developments and understand the scaling challenges for new–biologically inspired–learning models on leadership-class HPC resources.These emerging models feature sparse and random connectivity pro-files that map to more loosely-coupled parallel architectures with alarge number of CPU cores per node. Contrasted with traditional MLcodes, these methods exploit loosely-coupled sparse data structures asopposed to tightly-coupled dense matrix computations, which benefitfrom SIMD-style parallelism found on GPUs. In this paper we introducea hybrid Message Passing Interface (MPI) and Open Multi-Processing(OpenMP) parallelization scheme to accelerate and scale our computa-tional model based on the dynamics of cortical tissue. We ran compu-tational tests on a leadership class visualization and analysis cluster atArgonne National Laboratory. We include a study of strong and weakscaling, where we obtained parallel efficiency measures with a minimumabove 87\% and a maximum above 97\% for simulations of our biologicallyinspired neural network on up to 64 computing nodes running 8 threadseach. This study shows promise of the MPI+OpenMP hybrid approachto support flexible and biologically-inspired computational experimen-tal scenarios. In addition, we present the viability in the application ofthese strategies in high-end leadership computers in the future.},
	booktitle = {Parallel {Computing}: {Technology} {Trends}},
	author = {Dematties, Dario and Thiruvathukal, George K. and Rizzi, Silvio B. and Wainselboim, Alejandro and Zanutto, B. Silvano},
	editor = {Foster, Ian and Joubert, Gerhard R. and Kučera, Luděk and Nagel, Wolfgang E. and Peter, Frans},
	year = {2020},
	pages = {497--506},
}

@inproceedings{goel_survey_2020,
	title = {A {Survey} of {Methods} for {Low}-{Power} {Deep} {Learning} and {Computer} {Vision}},
	url = {http://ecommons.luc.edu/cs_facpubs/241},
	doi = {10.1109/WF-IoT48130.2020.9221198},
	abstract = {Deep neural networks (DNNs) are successful in many computer vision tasks. However, the most accurate DNNs require millions of parameters and operations, making them energy, computation and memory intensive. This impedes the deployment of large DNNs in low-power devices with limited compute resources. Recent research improves DNN models by reducing the memory requirement, energy consumption, and number of operations without significantly decreasing the accuracy. This paper surveys the progress of low-power deep learning and computer vision, specifically in regards to inference, and discusses the methods for compacting and accelerating DNN models. The techniques can be divided into four major categories: (1) parameter quantization and pruning, (2) compressed convolutional filters and matrix factorization, (3) network architecture search, and (4) knowledge distillation. We analyze the accuracy, advantages, disadvantages, and potential solutions to the problems with the techniques in each category. We also discuss new evaluation metrics as a guideline for future research.},
	booktitle = {2020 {IEEE} 6th {World} {Forum} on {Internet} of {Things} ({WF}-{IoT})},
	author = {Goel, Abhinav and Tung, Caleb and Lu, Yung-Hsiang and Thiruvathukal, George K.},
	month = jun,
	year = {2020},
	pages = {1--6},
}

@inproceedings{chakraborty_real-time_2020,
	title = {A {Real}-{Time} {Feature} {Indexing} {System} on {Live} {Video} {Streams}},
	url = {http://ecommons.luc.edu/cs_facpubs/249},
	doi = {10.1109/COMPSAC48688.2020.00016},
	abstract = {Most of the existing video storage systems rely on offline processing to support the feature-based indexing on video streams. The feature-based indexing technique provides an effective way for users to search video content through visual features, such as object categories (e.g., cars and persons). However, due to the reliance on offline processing, video streams along with their captured features cannot be searchable immediately after video streams are recorded. According to our investigation, buffering and storing live video steams are more time-consuming than the YOLO v3 object detector. Such observation motivates us to propose a real-time feature indexing (RTFI) system to enable instantaneous feature-based indexing on live video streams after video streams are captured and processed through object detectors. RTFI achieves its real-time goal via incorporating the novel design of metadata structure and data placement, the capability of modern object detector (i.e., YOLO v3), and the deduplication techniques to avoid storing repetitive video content. Notably, RTFI is the first system design for realizing real-time feature-based indexing on live video streams. RTFI is implemented on a Linux server and can improve the system throughput by upto 10.60x, compared with the base system without the proposed design. In addition, RTFI is able to make the video content searchable within 20 milliseconds for 10 live video streams after the video content is received by the proposed system, excluding the network transfer latency.},
	booktitle = {2020 {IEEE} 44th {Annual} {Computers}, {Software}, and {Applications} {Conference} ({COMPSAC})},
	author = {Chakraborty, Aditya and Pawar, Akshay and Jang, Hojoung and Huang, Shunqiao and Mishra, Sripath and Shuo-Han, Chen and Chang, Yan-Hao and Thiruvathukal, George K. and Lu, Yung-Hsiang},
	month = jul,
	year = {2020},
	note = {ISSN: 0730-3157},
	pages = {42--50},
}

@inproceedings{aghajanzadeh_camera_2020,
	title = {Camera {Placement} {Meeting} {Restrictions} of {Computer} {Vision}},
	url = {http://ecommons.luc.edu/cs_facpubs/250},
	doi = {10.1109/ICIP40778.2020.9190851},
	abstract = {In the blooming era of smart edge devices, surveillance cameras have been deployed in many locations. Surveillance cameras are most useful when they are spaced out to maximize coverage of an area. However, deciding where to place cameras is an NP-hard problem and researchers have proposed heuristic solutions. Existing work does not consider a significant restriction of computer vision: in order to track a moving object, the object must occupy enough pixels. The number of pixels depends on many factors (How far away is the object? What is the camera resolution? What is the focal length?). In this study, we propose a camera placement method that identifies effective camera placement in arbitrary spaces and can account for different camera types as well. Our strategy represents spaces as polygons, then uses a greedy algorithm to partition the polygons and determine the cameras’ locations to provide the desired coverage. Our solution also makes it possible to perform object tracking via overlapping camera placement. Our method is evaluated against complex shapes and real-world museum floor plans, achieving up to 85\% coverage and 25\% overlap.},
	booktitle = {2020 {IEEE} {International} {Conference} on {Image} {Processing} ({ICIP})},
	author = {Aghajanzadeh, Sara and Naidu, Roopasree and Chen, Shuo-Han and Tung, Caleb and Goel, Abhinav and Lu, Yung-Hsiang and Thiruvathukal, George K.},
	month = oct,
	year = {2020},
	note = {ISSN: 2381-8549},
	pages = {3254--3258},
}

@inproceedings{west_flic_2020,
	title = {{FLIC}: {A} {Distributed} {Fog} {Cache} for {City}-{Scale} {Applications}},
	url = {http://ecommons.luc.edu/cs_facpubs/243},
	doi = {10.1109/ICFC49376.2020.00019},
	abstract = {We present FLIC, a distributed software data caching framework for fogs that reduces network traffic and latency. FLIC is targeted toward city-scale deployments of cooperative IoT devices in which each node gathers and shares data with surrounding devices. As machine learning and other data processing techniques that require large volumes of training data are ported to low-cost and low-power IoT systems, we expect that data analysis will be moved away from the cloud. Separation from the cloud will reduce reliance on power-hungry centralized cloud-based infrastructure. However, city-scale deployments of cooperative IoT devices often connect to the Internet with cellular service, in which service charges are proportional to network usage. IoT system architects must be clever in order to keep costs down in these scenarios. To reduce the network bandwidth required to operate city-scale deployments of cooperative IoT systems, FLIC implements a distributed cache on the IoT nodes in the fog. FLIC allows the IoT network to share its data without repetitively interacting with a simple cloud storage service, reducing calls out to a backing store. Our results displayed a less than 2\% miss rate on reads. Thus, allowing for only 5\% of requests needing the backing store. We were also able to achieve more than 50\% reduction in bytes transmitted per second.},
	booktitle = {2020 {IEEE} {International} {Conference} on {Fog} {Computing} ({ICFC})},
	author = {West, Jack and Klingensmith, Neil and Thiruvathukal, George K.},
	month = apr,
	year = {2020},
	pages = {73--78},
}

@inproceedings{goel_low-power_2020,
	address = {New York, NY, USA},
	series = {{ISLPED} '20},
	title = {Low-{Power} {Object} {Counting} with {Hierarchical} {Neural} {Networks}},
	isbn = {978-1-4503-7053-0},
	url = {https://doi.org/10.1145/3370748.3406569},
	doi = {10.1145/3370748.3406569},
	abstract = {Deep Neural Networks (DNNs) achieve state-of-the-art accuracy in many computer vision tasks, such as object counting. Object counting takes two inputs: an image and an object query and reports the number of occurrences of the queried object. To achieve high accuracy, DNNs require billions of operations, making them difficult to deploy on resource-constrained, low-power devices. Prior work shows that a significant number of DNN operations are redundant and can be eliminated without affecting the accuracy. To reduce these redundancies, we propose a hierarchical DNN architecture for object counting. This architecture uses a Region Proposal Network (RPN) to propose regions-of-interest (RoIs) that may contain the queried objects. A hierarchical classifier then efficiently finds the RoIs that actually contain the queried objects. The hierarchy contains groups of visually similar object categories. Small DNNs at each node of the hierarchy classify between these groups. The RoIs are incrementally processed by the hierarchical classifier. If the object in an RoI is in the same group as the queried object, then the next DNN in the hierarchy processes the RoI further; otherwise, the RoI is discarded. By using a few small DNNs to process each image, this method reduces the memory requirement, inference time, energy consumption, and number of operations with negligible accuracy loss when compared with the existing techniques.},
	booktitle = {Proceedings of the {ACM}/{IEEE} {International} {Symposium} on {Low} {Power} {Electronics} and {Design}},
	publisher = {Association for Computing Machinery},
	author = {Goel, Abhinav and Tung, Caleb and Aghajanzadeh, Sara and Ghodgaonkar, Isha and Ghosh, Shreya and Thiruvathukal, George K. and Lu, Yung-Hsiang},
	year = {2020},
	note = {event-place: Boston, Massachusetts},
	pages = {163168},
}

@inproceedings{hu_crowdsourcing_2020,
	address = {New York, NY, USA},
	series = {{WWW} '20},
	title = {Crowdsourcing {Detection} of {Sampling} {Biases} in {Image} {Datasets}},
	isbn = {978-1-4503-7023-3},
	url = {https://doi.org/10.1145/3366423.3380063},
	doi = {10.1145/3366423.3380063},
	abstract = {Despite many exciting innovations in computer vision, recent studies reveal a number of risks in existing computer vision systems, suggesting results of such systems may be unfair and untrustworthy. Many of these risks can be partly attributed to the use of a training image dataset that exhibits sampling biases and thus does not accurately reflect the real visual world. Being able to detect potential sampling biases in the visual dataset prior to model development is thus essential for mitigating the fairness and trustworthy concerns in computer vision. In this paper, we propose a three-step crowdsourcing workflow to get humans into the loop for facilitating bias discovery in image datasets. Through two sets of evaluation studies, we find that the proposed workflow can effectively organize the crowd to detect sampling biases in both datasets that are artificially created with designed biases and real-world image datasets that are widely used in computer vision research and system development.},
	booktitle = {Proceedings of {The} {Web} {Conference} 2020},
	publisher = {Association for Computing Machinery},
	author = {Hu, Xiao and Wang, Haobo and Vegesana, Anirudh and Dube, Somesh and Yu, Kaiwen and Kao, Gore and Chen, Shuo-Han and Lu, Yung-Hsiang and Thiruvathukal, George K. and Yin, Ming},
	year = {2020},
	note = {event-place: Taipei, Taiwan},
	pages = {2955--2961},
}

@inproceedings{greenberg_integrating_2019,
	title = {Integrating {Mathematics} and {Educational} {Robotics}: {Simple} {Motion} {Planning}},
	url = {http://ecommons.luc.edu/cs_facpubs/213},
	abstract = {This paper shows how students can be guided to integrate elementary mathematical analyses with motion planning for typical educational robots. Rather than using calculus as in comprehensive works on motion planning, we show students can achieve interesting results using just simple linear regression tools and trigonometric analyses. Experiments with one robotics platform show that use of these tools can lead to passable navigation through dead reckoning even if students have limited experience with use of sensors, programming, and mathematics.},
	booktitle = {10th {International} {Conference} on {Robotics} in {Education} ({RiE})},
	author = {Greenberg, Ronald I. and Thiruvathukal, George K. and Greenberg, Sara T.},
	editor = {Verlag, Springer},
	year = {2019},
}

@inproceedings{eisty_use_2019,
	title = {Use of {Software} {Process} in {Research} {Software} {Development}: {A} {Survey}},
	url = {http://ecommons.luc.edu/cs_facpubs/214},
	doi = {10.1145/3319008.3319351},
	abstract = {Background: Developers face challenges in building high-quality research software due to its inherent complexity. These challenges can reduce the confidence users have in the quality of the result produced by the software. Use of a defined software development process, which divides the development into distinct phases, results in improved design, more trustworthy results, and better project management. Aims: This paper focuses on gaining a better understanding of the use of software development process for research software. Method: We surveyed research software developers to collect information about their use of software development processes. We analyze whether and demographic factors influence the respondents' use of and perceived value in defined process. Results: Based on 98 responses, research software developers appear to follow a defined software development process at least some of the time. The respondents also have a strong positive perception about the value of following processes. Conclusions: To produce high-quality and reliable research software, which is critical for many research domains, research software developers must follow a proper software development process. The results indicate a positive perception of value about using defined development processes that should lead to both short-term benefits through improved results and long-term benefits through more maintainable software.},
	booktitle = {Proceedings of the {Evaluation} and {Assessment} on {Software} {Engineering} ({EASE}) 2019},
	author = {Eisty, Nasir U. and Thiruvathukal, George K. and Carver, Jeffrey C.},
	year = {2019},
}

@inproceedings{greenberg_exercises_2019,
	title = {Exercises {Integrating} {High} {School} {Mathematics} with {Robot} {Motion} {Planning}},
	url = {http://ecommons.luc.edu/cs_facpubs/231},
	doi = {10.1109/FIE43999.2019.9028394},
	abstract = {This Innovative Practice Work in Progress presents progress in developing exercises for high school students incorporating level-appropriate mathematics into robotics activities. We assume mathematical foundations ranging from algebra to precalculus, whereas most prior work on integrating mathematics into robotics uses only very elementary mathematical reasoning or, at the other extreme, is comprised of technical papers or books using calculus and other advanced mathematics. The exercises suggested are relevant to any differential-drive robot, which is an appropriate model for many different varieties of educational robots. They guide students towards comparing a variety of natural navigational strategies making use of typical movement primitives. The exercises align with Common Core State Standards for Mathematics.},
	booktitle = {2019 {IEEE} {Frontiers} in {Education} {Conference} ({FIE})},
	author = {Greenberg, Ronald I. and Thiruvathukal, George K.},
	month = oct,
	year = {2019},
	note = {ISSN: 2377-634X},
}

@inproceedings{tung_large-scale_2019,
	title = {Large-{Scale} {Object} {Detection} of {Images} from {Network} {Cameras} in {Variable} {Ambient} {Lighting} {Conditions}},
	url = {http://ecommons.luc.edu/cs_facpubs/207},
	doi = {10.1109/MIPR.2019.00080},
	abstract = {Computer vision relies on labeled datasets for training and evaluation in detecting and recognizing objects. The popular computer vision program, YOLO ("You Only Look Once"), has been shown to accurately detect objects in many major image datasets. However, the images found in those datasets, are independent of one another and cannot be used to test YOLO's consistency at detecting the same object as its environment (e.g. ambient lighting) changes. This paper describes a novel effort to evaluate YOLO's consistency for large-scale applications. It does so by working (a) at large scale and (b) by using consecutive images from a curated network of public video cameras deployed in a variety of real-world situations, including traf?c intersections, national parks, shopping malls, university campuses, etc. We speci?cally examine YOLO's ability to detect objects in different scenarios (e.g., daytime vs. night), leveraging the cameras' ability to rapidly retrieve many successive images for evaluating detection consistency. Using our camera network and advanced computing resources (supercomputers), we analyzedmorethan5millionimagescapturedby140network cameras in 24 hours. Compared with labels marked by humans (considered as "ground truth"), YOLO struggles to consistently detect the same humans and cars as their positions change from one frame to the next; it also struggles to detect objects at night time. Our ?ndings suggest that state-of-the art vision solutions should be trained by data from network camera with contextual information before they can be deployed in applications that demand high consistency on object detection.},
	booktitle = {2019 {IEEE} {Conference} on {Multimedia} {Information} {Processing} and {Retrieval} ({MIPR})},
	author = {Tung, Caleb and Kelleher, Matthew R. and Schlueter, Ryan J. and Xu, Binhan and Lu, Yung-Hsiang and Thiruvathukal, George K. and Chen, Yen-Kuan. and Lu, Yang},
	month = mar,
	year = {2019},
	pages = {393--398},
}

@inproceedings{laufer_tests_2019,
	address = {New York, NY, USA},
	series = {Scala '19},
	title = {Tests as {Maintainable} {Assets} via {Auto}-{Generated} {Spies}: {A} {Case} {Study} {Involving} the {Scala} {Collections} {Library}'s {Iterator} {Trait}},
	isbn = {978-1-4503-6824-7},
	url = {https://doi.org/10.1145/3337932.3338814},
	doi = {10.1145/3337932.3338814},
	abstract = {In testing stateful abstractions, it is often necessary to record interactions, such as method invocations, and express assertions over these interactions. Following the Test Spy design pattern, we can reify such interactions programmatically through additional mutable state. Alternatively, a mocking framework, such as Mockito, can automatically generate test spies that allow us to record the interactions and express our expectations in a declarative domain-specific language. According to our study of the test code for Scala's Iterator trait, the latter approach can lead to a significant reduction of test code complexity in terms of metrics such as code size (in some cases over 70\% smaller), cyclomatic complexity, and amount of additional mutable state required. In this tools paper, we argue that the resulting test code is not only more maintainable, readable, and intentional, but also a better stylistic match for the Scala community than manually implemented, explicitly stateful test spies.},
	booktitle = {Proceedings of the {Tenth} {ACM} {SIGPLAN} {Symposium} on {Scala}},
	publisher = {Association for Computing Machinery},
	author = {Läufer, Konstantin and O'Sullivan, John and Thiruvathukal, George K.},
	year = {2019},
	note = {event-place: London, United Kingdom},
	pages = {17--21},
}

@inproceedings{kaseb_analyzing_2018,
	title = {Analyzing {Real}-{Time} {Multimedia} {Content} {From} {Network} {Cameras} {Using} {CPUs} and {GPUs} in the {Cloud}},
	url = {https://ecommons.luc.edu/cs_facpubs/190/},
	abstract = {Millions of network cameras are streaming real-time multimedia content (images or videos) for various environments (e.g., highways and malls) and can be used for a variety of applications. Analyzing the content from many network cameras requires significant amounts of computing resources. Cloud vendors offer resources in the form of cloud instances with different capabilities and hourly costs. Some instances include GPUs that can accelerate analysis programs. Doing so incurs additional monetary cost because instances with GPUs are more expensive. It is a challenging problem to reduce the overall monetary cost of using the cloud to analyze the real-time multimedia content from network cameras while meeting the desired analysis frame rates. This paper describes a cloud resource manager that solves this problem by estimating the resource requirements of executing analysis programs using CPU or GPU, formulating the resource allocation problem as a multiple-choice vector bin packing problem, and solving it using an existing algorithm. The experiments show that the manager can reduce up to 61\% of the cost compared with other allocation strategies.},
	booktitle = {{IEEE} {International} {Conference} on {Multimedia} {Information} {Processing} and {Retrieval}},
	author = {Kaseb, Ahmed S. and Fu, Bo and Mohan, Anup and Lu, Yung-Hsiang and Reibman, Amy and Thiruvathukal, George K.},
	year = {2018},
}

@inproceedings{surakitbanharn_cross-referencing_2018,
	title = {Cross-{Referencing} {Social} {Media} and {Public} {Surveillance} {Camera} {Data} for {Disaster} {Response}},
	url = {https://ecommons.luc.edu/cs_facpubs/203/},
	doi = {10.1109/THS.2016.7568911},
	abstract = {Physical media (like surveillance cameras) and social media (like Instagram and Twitter) may both be useful in attaining on-the-ground information during an emergency or disaster situation. However, the intersection and reliability of both surveillance cameras and social media during a natural disaster are not fully understood. To address this gap, we tested whether social media is of utility when physical surveillance cameras went off-line during Hurricane Irma in 2017. Specifically, we collected and compared geo-tagged Instagram and Twitter posts in the state of Florida during times and in areas where public surveillance cameras went off-line. We report social media content and frequency and content to determine the utility for emergency managers or first responders during a natural disaster.},
	booktitle = {{IEEE} {Symposium} on {Technologies} for {Homeland} {Security}},
	author = {Surakitbanharn, Chittayong and Yau, Calvin and Wang, Guizhen and Chawla, Aniesh and Pan, Yinuo and Sun, Zhaoya and Yellin, Sam and Ebert, David and Lu, Yung-Hsiang and Thiruvathukal, George K.},
	month = oct,
	year = {2018},
}

@inproceedings{eisty_survey_2018,
	title = {A {Survey} of {Software} {Metric} {Use} in {Research} {Software} {Development}},
	url = {https://ecommons.luc.edu/cs_facpubs/206/},
	doi = {10.1109/eScience.2018.00036},
	abstract = {Background: Breakthroughs in research increasingly depend on complex software libraries, tools, and applications aimed at supporting specific science, engineering, business, or humanities disciplines. The complexity and criticality of this software motivate the need for ensuring quality and reliability. Software metrics are a key tool for assessing, measuring, and understanding software quality and reliability. Aims: The goal of this work is to better understand how research software developers use traditional software engineering concepts, like metrics, to support and evaluate both the software and the software development process. One key aspect of this goal is to identify how the set of metrics relevant to research software corresponds to the metrics commonly used in traditional software engineering. Method: We surveyed research software developers to gather information about their knowledge and use of code metrics and software process metrics. We also analyzed the influence of demographics (project size, development role, and development stage) on these metrics. Results: The survey results, from 129 respondents, indicate that respondents have a general knowledge of metrics. However, their knowledge of specific SE metrics is lacking, their use even more limited. The most used metrics relate to performance and testing. Even though code complexity often poses a significant challenge to research software development, respondents did not indicate much use of code metrics. Conclusions: Research software developers appear to be interested and see some value in software metrics but may be encountering roadblocks when trying to use them. Further study is needed to determine the extent to which these metrics could provide value in continuous process improvement.},
	booktitle = {2018 {IEEE} 14th {International} {Conference} on e-{Science} (e-{Science})},
	author = {Eisty, Nasir U. and Thiruvathukal, George K. and Carver, Jeffrey C.},
	month = oct,
	year = {2018},
	pages = {212--222},
}

@inproceedings{kaseb_analyzing_2018-1,
	title = {Analyzing {Real}-{Time} {Multimedia} {Content} from {Network} {Cameras} {Using} {CPUs} and {GPUs} in the {Cloud}},
	url = {https://ecommons.luc.edu/cs_facpubs/190/},
	doi = {10.1109/MIPR.2018.00020},
	abstract = {Millions of network cameras are streaming real-time multimedia content (images or videos) for various environments (e.g., highways and malls) and can be used for a variety of applications. Analyzing the content from many network cameras requires significant amounts of computing resources. Cloud vendors offer resources in the form of cloud instances with different capabilities and hourly costs. Some instances include GPUs that can accelerate analysis programs. Doing so incurs additional monetary cost because instances with GPUs are more expensive. It is a challenging problem to reduce the overall monetary cost of using the cloud to analyze the real-time multimedia content from network cameras while meeting the desired analysis frame rates. This paper describes a cloud resource manager that solves this problem by estimating the resource requirements of executing analysis programs using CPU or GPU, formulating the resource allocation problem as a multiple-choice vector bin packing problem, and solving it using an existing algorithm. The experiments show that the manager can reduce up to 61\% of the cost compared with other allocation strategies.},
	booktitle = {2018 {IEEE} {Conference} on {Multimedia} {Information} {Processing} and {Retrieval} ({MIPR})},
	author = {Kaseb, Ahmed S. and Fu, Bo and Mohan, Anup and Lu, Yung-Hsiang and Reibman, Amy and Thiruvathukal, George K.},
	month = apr,
	year = {2018},
	pages = {69--74},
}

@inproceedings{alyamkin_2018_2018,
	title = {2018 {Low}-{Power} {Image} {Recognition} {Challenge}: {Status}, {Challenegs}, {Opportunities}},
	url = {https://ecommons.luc.edu/cs_facpubs/217/},
	abstract = {Computer vision has achieved impressive progress in recent years. Meanwhile, mobile phones have become the primary computing platforms for millions of people. In addition to mobile phones, many autonomous systems rely on visual data for making decisions and some of these systems have limited energy (such as unmanned aerial vehicles also called drones and mobile robots). These systems rely on batteries and energy efficiency is critical. This article serves two main purposes: (1) Examine the state-of-the-art for low-power solutions to detect objects in images. Since 2015, the IEEE Annual International Low-Power Image Recognition Challenge (LPIRC) has been held to identify the most energy-efficient computer vision solutions. This article summarizes 2018 winners' solutions. (2) Suggest directions for research as well as opportunities for low-power computer vision.},
	booktitle = {{arXiv}:1810.01732},
	author = {Alyamkin, Sergei and Ardi, Matthew and Brighton, Achille and Berg, Alexander C. and Chen, Yiran and Cheng, Hsin-Pai and Chen, Bo and Fan, Zichen and Feng, Chen and Fu, Bo and Gauen, Kent and Go, Jongkook and Goncharenko, Alexander and Guo, Xuyang and Nguyen, Hong Hanh and Howard, Andrew and Huang, Yuanjun and Kang, Donghyun and Kim, Jaeyoun and Kondratyev, Alexander and Lee, Seungjae and Lee, Suwoong and Lee, Junhyeok and Liang, Zhiyu and Liu, Xin and Liu, Juzheng and Li, Zichao and Lu, Yang and Lu, Yung-Hsiang and Malik, Deeptanshu and Park, Eunbyung and Repin, Denis and Sheng, Tao and Shen, Liang and Sun, Fei and Svitov, David and Thiruvathukal, George K. and Zhang, Baiwu and Zhang, Jingchi and Zhang, Xiaopeng and Zhuo, Shaojie},
	year = {2018},
}

@inproceedings{lewis_distributed_2017,
	address = {ACM, 2 Penn Plaza, Suite 701, New York, NY 10121-0701, USA},
	title = {A {Distributed} {Graph} {Approach} for {Pre}-processing {Linked} {RDF} {Data} {Using} {Supercomputers}},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	isbn = {978-1-4503-4987-1},
	url = {https://ecommons.luc.edu/cs_facpubs/139/},
	abstract = {Efficient RDF, graph based queries are becoming more pertinent based on the increased interest in data analytics and its intersection with large, unstructured but connected data. Many commercial systems have adopted distributed RDF graph systems in order to handle increasing dataset sizes and complex queries. This paper introduces a distribute graph approach to pre-processing linked data. Instead of traversing the memory graph, our system indexes pre-processed join elements that are organized in a graph structure. We analyze the Dbpedia data-set (derived from the Wikipedia corpus) and compare our access method to the graph traversal access approach which we also devise. Results show from our experiments that the distributed, pre-processed graph approach to accessing linked data is faster than the traversal approach over a specific range of linked queries.},
	booktitle = {Workshop on {Semantic} {Big} {Data} ({SBD} 2018) at {ACM} {SIGMOD}},
	author = {Lewis, Mike and Thiruvathukal, George K. and Vishwanath, Venkatram and Papka, Michael and Johnson, Andrew},
	year = {2017},
}

@inproceedings{gauen_comparison_2017,
	title = {Comparison of {Visual} {Datasets} for {Machine} {Learning}},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	url = {https://ecommons.luc.edu/cs_facpubs/148/},
	abstract = {One of the greatest technological improvements in recent years is the rapid progress using machine learning for processing visual data. Among all factors that contribute to this development, datasets with labels play crucial roles. Several datasets are widely reused for investigating and analyzing different solutions in machine learning. Many systems, such as autonomous vehicles, rely on components using machine learning for recognizing objects. This paper compares different visual datasets and frameworks for machine learning. The comparison is both qualitative and quantitative and investigates object detection labels with respect to size, location, and contextual information. This paper also presents a new approach creating datasets using real-time, geo-tagged visual data, greatly improving the contextual information of the data. The data could be automatically labeled by cross-referencing information from other sources (such as weather).},
	booktitle = {{IEEE} {Conference} on {Information} {Reuse} and {Integration} 2017},
	author = {Gauen, Kent and Dailey, Ryan and Laiman, John and Zi, Yuxiang and Asokan, Nirmal and Lu, Yung-Hsiang and Thiruvathukal, George K. and Shyu, Mei-Ling and Chen, Shu-Ching},
	year = {2017},
	pages = {346--355},
}

@inproceedings{dennis_computer_2017,
	title = {Computer {Science} and {Cultural} {History}: {A} {Dialogue}},
	url = {https://ecommons.luc.edu/history_facpubs/42/},
	booktitle = {{CESTEMER} {Conference}: {Cultivating} {Ensembles} in {STEM} {Education} and {Research}},
	author = {Dennis, David B. and Thiruvathukal, George K.},
	year = {2017},
}

@inproceedings{decker_research_2016,
	address = {Piscataway, NJ},
	title = {Research on {Equity} and {Sustained} {Participation} in {Engineering}, {Computing}, and {Technology} ({RESPECT}) {RESPECT} 2016},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	shorttitle = {2016 {Research} on {Equity} and {Sustained} {Participation} in {Engineering}, {Computing}, and {Technology} ({RESPECT}) {RESPECT} 2016},
	urldate = {2018-01-07},
	publisher = {IEEE},
	author = {Decker, Adrienne and Payton, Jamie and Eiselt, Kurt and Barnes, Tiffany and Thiruvathukal, George K.},
	year = {2016},
}

@inproceedings{honig_framework_2015,
	title = {A {Framework} {Architecture} for {Student} {Learning} in {Distributed} {Embedded} {Systems}},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	url = {https://ecommons.luc.edu/cs_facpubs/257/},
	abstract = {Academic courses focused on individual microcomputers or client/server applications are no longer sufficient for students to develop knowledge in embedded systems. Current and near-term industrial systems employ multiple interacting components and new network and security approaches; hence, academic preparation requires teaching students to develop realistic projects comparable to these real-world products. However, the complexity, breadth, and technical variations of these real-world products are difficult to reproduce in the classroom. This paper outlines preliminary work on a framework architecture suitable for academic teaching of modern embedded systems including the Internet of Things. It defines four layers, two of which are at the edges of the network, and not adequately covered in academia. For each layer of the architecture, specific technology and suitable devices are identified. Desired academic outcomes for courses using projects based on the architecture are identified. Feedback and comparison is sought on how effective student course and research activities based on the framework will be to real-world embedded systems developers.},
	booktitle = {10th {IEEE} {International} {Symposium} on {Industrial} {Embedded} {Systems} ({SIES})},
	author = {Honig, William and Läufer, Konstantin and Thiruvathukal, George K.},
	year = {2015},
	pages = {1--4},
}

@inproceedings{barnes_proceedings_2015,
	title = {Proceedings of 2015 {Research} on {Equity} and {Sustained} {Participation} in {Engineering}, {Computing}, and {Technology} ({RESPECT}) {RESPECT} 2015},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	urldate = {2018-01-07},
	booktitle = {Research on {Equity} and {Sustained} {Participation} in {Engineering}, {Computing}, and {Technology} ({RESPECT}) {RESPECT} 2015},
	author = {Barnes, Tiffany and Thiruvathukal, George K. and Boyer, Kristy Elizabeth and Forbes, Jeff and Payton, Jamie},
	year = {2015},
}

@inproceedings{borg_single_2014,
	title = {Single {Page} {Apps} for {Humanists}: {A} {Case} {Study} {Using} the {Perseus} {Richmond} {Times} {Corpus}},
	url = {http://dharchive.org/paper/DH2014/Paper-888.xml},
	abstract = {TEI is good at what it does: static documents rendered in glorious detail. But TEI is old. Its age doesn’t make TEI irrelevant, but it’s important to be conscious of how the way we weave the fabric of the web has changed since TEI was conceived in 1994, and reevaluate some of our assumptions about its use. In this early work, we are exploring this rethinking as part of a larger study within the center on general methods for isolating the complexity frequently associated with XML-based frameworks.},
	booktitle = {Proceedings of {Digital} {Humanities} 2014 ({DH2014})},
	author = {Borg, Trevor and Thiruvathukal, George K.},
	year = {2014},
}

@inproceedings{carver_software_2013,
	title = {Software {Engineering} {Need} not be {Difficult}},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	url = {https://ecommons.luc.edu/cs_facpubs/75},
	abstract = {"Progress in scientific research is dependent on the quality and accessibility of software at all levels" (the overall premise of the workshop). We argue that true progress depends on embracing the best traditional–and emergent– practices in software engineering, especially agile practices that intersect with the tradition of software engineering. Software engineering as practiced today is more than the stereotypical monolithic lifecycle processes (e.g. waterfall, spiral, etc.) that historically have impeded progress for small/medium sized development efforts. In addition, the discipline and practice of software engineering includes software quality (with an established tradition of software metrics). Software processes can be pragmatic and use best features/practices of various models without impeding developer productivity. The embracement of these practices may also be important to prevent a brain drain of sorts, as students are increasingly eschewing traditional scientific/computation science research in favor of industry opportunities, where they can literally apply what they have learned in software development courses where pragmatic software engineering practices (e.g. test-driven design, RESTful architecture, etc.) are already prevalent."},
	booktitle = {{WSSSPE} 2013},
	publisher = {Figshare},
	author = {Carver, Jeffrey C. and Thiruvathukal, George K.},
	year = {2013},
}

@inproceedings{kaylor_simplifying_2012,
	title = {Simplifying {Domain} {Modeling} and {Memory} {Management} in {User}-{Mode} {Filesystems} with the {NOFS} {Framework}},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	url = {https://ecommons.luc.edu/cs_facpubs/62/},
	booktitle = {International {Conference} on {Electro} {Information} {Technology} 2012},
	author = {Kaylor, Joe P. and {Läufer} and Thiruvathukal, George K.},
	year = {2012},
}

@inproceedings{kaylor_restfs_2011-1,
	address = {ACM, 2 Penn Plaza, Suite 701, New York, NY 10121-0701, USA},
	title = {{RestFS}: {Resources} are {Filesystems}, too},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	isbn = {978-1-4503-0623-2},
	url = {https://ecommons.luc.edu/cs_facpubs/15/},
	abstract = {We have designed and implemented RestFS, a software framework that provides a uniform, configurable connector layer for mapping remote web-based resources to local filesystem-based resources, recognizing the similarity between these two types of resources. Such mappings enable programmatic access to a resource, as well as composition of two or more resources, through the local operating system's standard filesystem application programming interface (API), scriptable file-based command-line utilities, and inter-process communication (IPC) mechanisms. The framework supports automatic and manual authentication. We include several examples intended to show the utility and practicality of our framework.},
	booktitle = {Second {International} {Workshop} / {RESTful} {Design} ({WS}-{REST} '11)},
	author = {Kaylor, Joe P. and Läufer, Konstantin and Thiruvathukal, George K.},
	year = {2011},
}

@inproceedings{jones_object_2011,
	title = {The {Object} of {Platform} {Studies}: {Relational} {Materialities} and the {Social} {Platform} (the {Case} of the {Nintendo} {Wii})},
	url = {https://ecommons.luc.edu/cs_facpubs/28/},
	abstract = {Racing the Beam: The Atari Video Computer System,by Ian Bogost and Nick Montfort, inaugurated thePlatform Studies series at MIT Press in 2009.We’ve coauthored a new book in the series, Codename: Revolution: the Nintendo Wii Video Game Console. Platform studies is a quintessentially Digital Humanities approach, since it’s explicitly focused on the interrelationship of computing and cultural expression. According to the series preface, the goal of platform studies is “to consider the lowest level of computing systems and to understand how these systems relate to culture and creativity.”In practice, this involves paying close attentionto specific hardware and software interactions–to the vertical relationships between a platform’s multilayered materialities (Hayles; Kirschenbaum),from transistors to code to cultural reception. Any given act of platform-studies analysis may focus for example on the relationship between the chipset and the OS, or between the graphics processor and display parameters or game developers’ designs.In computing terms, platform is an abstraction(Bogost and Montfort), a pragmatic frame placed around whatever hardware-and-software configuration is required in order to build or run certain specificapplications (including creative works). The object of platform studies is thus a shifting series of possibility spaces, any number of dynamic thresholds between discrete levels of a system.},
	booktitle = {Digital {Humanities} 2011 ({DH2011})},
	author = {Jones, Steven E. and Thiruvathukal, George K.},
	year = {2011},
	pages = {163--164},
}

@inproceedings{thiruvathukal_e-carrel_2010,
	title = {E-{Carrel}: {An} {Environment} for {Collaborative} {Textual} {Scholarship}},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	shorttitle = {E-{Carrel}},
	url = {https://ecommons.luc.edu/cs_facpubs/1},
	abstract = {The E-Carrel project aims to address the preservation of, access to, and re-uses of humanities electronic text files. It enables dynamic, growing resource projects as repositories for new knowledge. It provides for on-line distributed data and tools that are open to new scholarly enhancement through a user friendly tagging tool, sophisticated use of stand-off markup and annotation (leveraging RDF capabilities), and a browsing system anyone can use. It creates a secure system of text preparation and dissemination that encourages collaboration and participation by anyone interested in the texts. To insure the endurance of authenticated texts, multiple copies are distributed on the Internet. Foundation texts anchor a system for maintaining and growing project usefulness beyond the originators\&rsquo; interest and the functions they imagined. Increasing access to humanities texts as useful, adaptable, reliable source materials that can be re-purposed will increase interest in continued maintenance, which are critical for long-term preservation and access.},
	urldate = {2018-01-07},
	publisher = {The University of Chicago},
	author = {Thiruvathukal, George K. and Jones, Steven E. and Shillingsburg, Peter},
	year = {2010},
}

@article{matthews_shape-based_2021,
	title = {Shape-{Based} {Classification} of {Partially} {Observed} {Curves}, {With} {Applications} to {Anthropology}},
	volume = {7},
	issn = {2297-4687},
	url = {https://www.frontiersin.org/article/10.3389/fams.2021.759622},
	doi = {10.3389/fams.2021.759622},
	abstract = {We consider the problem of classifying curves when they are observed only partially on their parameter domains. We propose computational methods for (i) completion of partially observed curves; (ii) assessment of completion variability through a nonparametric multiple imputation procedure; (iii) development of nearest neighbor classifiers compatible with the completion techniques. Our contributions are founded on exploiting the geometric notion of shape of a curve, defined as those aspects of a curve that remain unchanged under translations, rotations and reparameterizations. Explicit incorporation of shape information into the computational methods plays the dual role of limiting the set of all possible completions of a curve to those with similar shape while simultaneously enabling more efficient use of training data in the classifier through shape-informed neighborhoods. Our methods are then used for taxonomic classification of partially observed curves arising from images of fossilized Bovidae teeth, obtained from a novel anthropological application concerning paleoenvironmental reconstruction.},
	journal = {Frontiers in Applied Mathematics and Statistics},
	author = {Matthews, Gregory J. and Bharath, Karthik and Kurtek, Sebastian and Brophy, Juliet K. and Thiruvathukal, George K. and Harel, Ofer},
	year = {2021},
	pages = {70},
}

@article{dailey_automated_2021,
	title = {Automated {Discovery} of {Network} {Cameras} {inHeterogeneous} {Web} {Pages}},
	url = {https://ecommons.luc.edu/cs_facpubs/TBD/},
	doi = {TBD},
	abstract = {Reduction in the cost of Network Cameras along with a rise in connectivity enables entities all around the world to deploy vast arrays of camera networks. Network cameras offer real-time visual data that can be used for studying traffic patterns, emergency response, security, and other applications. Although many sources of Network Camera data are available, collecting the data remains difficult due to variations in programming interface and website structures. Previous solutions rely on manually parsing the target website, taking many hours to complete. We create a general and automated solution for aggregating Network Camera data spread across thousands of uniquely structured webpages. We analyze heterogeneous webpage structures and identify common characteristics among 73 sample Network Camera websites (each website has multiple web pages). These characteristics are then used to build an automated camera discovery module that crawls and aggregates Network Camera data. Our system successfully extracts 57,364 Network Cameras from 237,257 unique web pages.},
	author = {Dailey, Ryan and Chawla, Aniesh and Liu, Andrew and Mishra, Sripath and Zhang, Ling and Majors, Josh and Lu, Yung-Hsiang and Thiruvathukal, George K.},
	year = {2021},
}

@article{dematties_towards_2020-1,
	title = {Towards {High}-{End} {Scalability} on {Bio}-{Inspired} {Computational} {Models}},
	url = {https://ecommons.luc.edu/cs_facpubs/253/},
	doi = {10.6084/m9.figshare.12762260.v2},
	abstract = {Presentation at CyberColombia's Third HPC Summer School: Bio and Data Science Part 1 describes our work on developing a neurocomputational model inspired in specific features found in the mammalian cortex. Part 2 describes our software development efforts to build an HPC version of our work aimed at scalability on leadership class supercomputers, including a discussion of our strong and weak scaling results to date. Part 3 describes our efforts with software engineering and reproducibilty with a discussion of best practices for working with open source and hosting code, datasets, and analyses.},
	author = {Dematties, Dario and Rizzi, Silvio B. and Thiruvathukal, George K.},
	month = aug,
	year = {2020},
}

@article{dematties_computational_2020,
	title = {A {Computational} {Theory} for the {Emergence} of {Grammatical} {Categories} in {Cortical} {Dynamics}},
	volume = {14},
	issn = {1662-5110},
	url = {https://www.frontiersin.org/article/10.3389/fncir.2020.00012},
	doi = {10.3389/fncir.2020.00012},
	abstract = {A general agreement in psycholinguistics claims that syntax and meaning are unified precisely and very quickly during online sentence processing. Although several theories have advanced arguments regarding the neurocomputational bases of this phenomenon, we argue that these theories could potentially benefit by including neurophysiological data concerning cortical dynamics constraints in brain tissue. In addition, some theories promote the integration of complex optimization methods in neural tissue. In this paper we attempt to fill these gaps introducing a computational model inspired in the dynamics of cortical tissue. In our modeling approach, proximal afferent dendrites produce stochastic cellular activations, while distal dendritic branches–on the other hand–contribute independently to somatic depolarization by means of dendritic spikes, and finally, prediction failures produce massive firing events preventing formation of sparse distributed representations. The model presented in this paper combines semantic and coarse-grained syntactic constraints for each word in a sentence context until grammatically related word function discrimination emerges spontaneously by the sole correlation of lexical information from different sources without applying complex optimization methods. By means of support vector machine techniques, we show that the sparse activation features returned by our approach are well suited—bootstrapping from the features returned by Word Embedding mechanisms—to accomplish grammatical function classification of individual words in a sentence. In this way we develop a biologically guided computational explanation for linguistically relevant unification processes in cortex which connects psycholinguistics to neurobiological accounts of language. We also claim that the computational hypotheses established in this research could foster future work on biologically-inspired learning algorithms for natural language processing applications.},
	journal = {Frontiers in Neural Circuits},
	author = {Dematties, Dario and Rizzi, Silvio and Thiruvathukal, George K. and Pérez, Mauricio David and Wainselboim, Alejandro and Zanutto, B. Silvano},
	year = {2020},
	pages = {12},
}

@article{brophy_analysis_2019,
	title = {An {Analysis} of the {Effect} of {Tooth} {Wear} on {Bovid} {Identification}},
	volume = {115},
	url = {https://www.sajs.co.za/article/view/5496},
	doi = {10.17159/sajs.2019/5496},
	abstract = {Previous research provides a method for reducing the subjectivity in molar tooth identification of animals in the family Bovidae, by quantifying the occlusal surface of teeth using elliptical Fourier analysis. This current paper specifically tests what effect teeth with medium to late wear have on the identification of bovid teeth when using the form (size and shape) of the occlusal surface to classify specimens.},
	journal = {South African Journal of Science},
	author = {Brophy, Juliet K. and Matthews, Gregory J. and Thiruvathukal, George K.},
	month = jul,
	year = {2019},
}

@article{alyamkin_low-power_2019,
	title = {Low-{Power} {Computer} {Vision}: {Status}, {Challenges}, and {Opportunities}},
	volume = {9},
	issn = {2156-3365},
	url = {http://ecommons.luc.edu/cs_facpubs/217},
	doi = {10.1109/JETCAS.2019.2911899},
	abstract = {Computer vision has achieved impressive progress in recent years. Meanwhile, mobile phones have become the primary computing platforms for millions of people. In addition to mobile phones, many autonomous systems rely on visual data for making decisions, and some of these systems have limited energy (such as unmanned aerial vehicles also called drones and mobile robots). These systems rely on batteries, and energy efficiency is critical. This paper serves the following two main purposes. First, examine the state of the art for low-power solutions to detect objects in images. Since 2015, the IEEE Annual International Low-Power Image Recognition Challenge (LPIRC) has been held to identify the most energy-efficient computer vision solutions. This paper summarizes the 2018 winners' solutions. Second, suggest directions for research as well as opportunities for low-power computer vision.},
	number = {2},
	journal = {IEEE Journal on Emerging and Selected Topics in Circuits and Systems},
	author = {Alyamkin, Sergei and Ardi, Matthew and Berg, Alexander C. and Brighton, Achille and Chen, Bo and Chen, Yiran and Cheng, Hsin-Pai and Fan, Zichen and Feng, Chen and Fu, Bo and Gauen, Kent and Goel, Abhinav and Goncharenko, Alexander and Guo, Xuyang and Ha, Soonhoi and Howard, Andrew and Hu, Xiao and Huang, Yuanjun and Kang, Donghyun and Kim, Jaeyoun and Ko, Jong Gook and Kondratyev, Alexander and Lee, Junhyeok and Lee, Seungjae and Lee, Suwoong and Li, Zichao and Liang, Zhiyu and Liu, Juzheng and Liu, Xin and Lu, Yang and Lu, Yung-Hsiang and Malik, Deeptanshu and Nguyen, Hong Hanh and Park, Eunbyung and Repin, Denis and Shen, Liang and Sheng, Tao and Sun, Fei and Svitov, David and Thiruvathukal, George K. and Zhang, Baiwu and Zhang, Jingchi and Zhang, Xiaopeng and Zhuo, Shaojie},
	month = jun,
	year = {2019},
	pages = {411--421},
}

@article{dematties_phonetic_2019,
	title = {Phonetic {Acquisition} in {Cortical} {Dynamics}, a {Computational} {Approach}},
	volume = {14},
	url = {https://doi.org/10.1371/journal.pone.0217966},
	doi = {10.1371/journal.pone.0217966},
	abstract = {Many computational theories have been developed to improve artificial phonetic classification performance from linguistic auditory streams. However, less attention has been given to psycholinguistic data and neurophysiological features recently found in cortical tissue. We focus on a context in which basic linguistic units–such as phonemes–are extracted and robustly classified by humans and other animals from complex acoustic streams in speech data. We are especially motivated by the fact that 8-month-old human infants can accomplish segmentation of words from fluent audio streams based exclusively on the statistical relationships between neighboring speech sounds without any kind of supervision. In this paper, we introduce a biologically inspired and fully unsupervised neurocomputational approach that incorporates key neurophysiological and anatomical cortical properties, including columnar organization, spontaneous micro-columnar formation, adaptation to contextual activations and Sparse Distributed Representations (SDRs) produced by means of partial N-Methyl-D-aspartic acid (NMDA) depolarization. Its feature abstraction capabilities show promising phonetic invariance and generalization attributes. Our model improves the performance of a Support Vector Machine (SVM) classifier for monosyllabic, disyllabic and trisyllabic word classification tasks in the presence of environmental disturbances such as white noise, reverberation, and pitch and voice variations. Furthermore, our approach emphasizes potential self-organizing cortical principles achieving improvement without any kind of optimization guidance which could minimize hypothetical loss functions by means of–for example–backpropagation. Thus, our computational model outperforms multiresolution spectro-temporal auditory feature representations using only the statistical sequential structure immerse in the phonotactic rules of the input stream.},
	number = {6},
	journal = {PLOS ONE},
	author = {Dematties, Dario and Rizzi, Silvio B. and Thiruvathukal, George K. and Wainselboim, Alejandro and Zanutto, B. Silvano},
	month = jun,
	year = {2019},
	note = {Publisher: Public Library of Science},
	pages = {1--28},
}

@article{matthews_comparison_2018,
	title = {A {Comparison} of {Machine} {Learning} {Techniques} for {Taxonomic} {Classification} of {Teeth} from the {Family} {Bovidae}},
	volume = {45},
	url = {https://doi.org/10.1080/02664763.2018.1441381},
	doi = {10.1080/02664763.2018.1441381},
	abstract = {This study explores the performance of modern, accurate machine learning algorithms on the classification of fossil teeth in the Family Bovidae. Isolated bovid teeth are typically the most common fossils found in southern Africa and they often constitute the basis for paleoenvironmental reconstructions. Taxonomic identification of fossil bovid teeth, however, is often imprecise and subjective. Using modern teeth with known taxons, machine learning algorithms can be trained to classify fossils. Previous work by Brophy et. al. 2014 uses elliptical Fourier analysis of the form (size and shape) of the outline of the occlusal surface of each tooth as features in a linear discriminant analysis framework. This manuscript expands on that previous work by exploring how different machine learning approaches classify the teeth and testing which technique is best for classification. Five different machine learning techniques including linear discriminant analysis, neural networks, nuclear penalized multinomial regression, random forests, and support vector machines were used to estimate these models. Support vector machines and random forests perform the best in terms of both log-loss and misclassification rate; both of these methods are improvements over linear discriminant analysis. With the identification and application of these superior methods, bovid teeth can be classified with higher accuracy.},
	number = {15},
	journal = {Journal of Applied Statistics},
	author = {Matthews, Gregory J. and Brophy, Juliet K. and Gu, Hongie and Luetkemeier, Maxwell P. and Thiruvathukal, George K.},
	year = {2018},
	note = {Publisher: Taylor and Francis},
	pages = {2773--2787},
}

@article{matthews_examining_2017,
	title = {Examining the {Use} of {Amazon}'s {Mechanical} {Turk} for {Edge} {Extraction} of the {Occlusal} {Surface} of {Fossilized} {Bovid} {Teeth}.},
	volume = {12},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	url = {https://ecommons.luc.edu/cs_facpubs/150/},
	abstract = {In order to reconstruct environments associated with Plio-Pleistocene hominins in southern Africa, researchers frequently rely upon the animals associated with the hominins, in particular, animals in the Family Bovidae. Bovids in southern Africa are typically identified by their teeth. However, identifying the taxon of a bovid tooth is challenging due to various biasing factors. Furthermore, inaccurate identification of fossil bovids can have significant consequences on the reconstructed paleoenvironment. Recent research on the classification of bovid fossil teeth has relied on using elliptical Fourier analysis to summarize the shape of the outline of the occlusal surface of the tooth and the resulting harmonic amplitudes. Currently, an expert in the field must manually place landmarks around the edges of each tooth which is slow and time consuming. This study tests whether it is possible to crowdsource this task, while maintaining the necessary level of quality needed to perform a statistical analysis on each tooth. Amazon Mechanical Turk workers place landmarks on the edge of the tooth which is compared to the performance of an expert in the field. The results suggest that crowdsourcing the digitization process is reliable and replicable. With the technical aspects of digitization managed, researchers can concentrate on analyzing and interpreting the data.},
	number = {7},
	journal = {PLOS ONE},
	author = {Matthews, Gregory J. and Thiruvathukal, George K. and Luetkemeier, Matthew P. and Brophy, Juliet K.},
	year = {2017},
}

@article{reisman_polyglot_2016,
	title = {A {Polyglot} {Approach} to {Bioinformatics} {Data} {Integration}: {A} {Phylogenetic} {Analysis} of {HIV}-1},
	volume = {12},
	url = {https://doi.org/10.4137/EBO.S32757},
	doi = {10.4137/EBO.S32757},
	abstract = {As sequencing technologies continue to drop in price and increase in throughput, new challenges emerge for the management and accessibility of genomic sequence data. We have developed a pipeline for facilitating the storage, retrieval, and subsequent analysis of molecular data, integrating both sequence and metadata. Taking a polyglot approach involving multiple languages, libraries, and persistence mechanisms, sequence data can be aggregated from publicly available and local repositories. Data are exposed in the form of a RESTful web service, formatted for easy querying, and retrieved for downstream analyses. As a proof of concept, we have developed a resource for annotated HIV-1 sequences. Phylogenetic analyses were conducted for {\textgreater}6,000 HIV-1 sequences revealing spatial and temporal factors influence the evolution of the individual genes uniquely. Nevertheless, signatures of origin can be extrapolated even despite increased globalization. The approach developed here can easily be customized for any species of interest.},
	journal = {Evolutionary Bioinformatics},
	author = {Reisman, Steven and Hatzopoulos, Thomas and Läufer, Konstantin and Thiruvathukal, George K. and Putonti, Catherine},
	year = {2016},
	pmid = {26819543},
	note = {\_eprint: https://doi.org/10.4137/EBO.S32757},
	pages = {EBO.S32757},
}

@article{tung_why_2022,
	title = {Why {Accuracy} is {Not} {Enough}: {The} {Need} for {Consistency} in {Object} {Detection}},
	volume = {29},
	doi = {10.1109/MMUL.2022.3175239},
	number = {3},
	journal = {IEEE MultiMedia},
	author = {Tung, Caleb and Goel, Abhinav and Bordwell, Fischer and Eliopoulos, Nick and Hu, Xiao and Lu, Yung-Hsiang and Thiruvathukal, George K.},
	year = {2022},
	pages = {8--16},
}

@article{tung_why_2022-1,
	title = {Why {Accuracy} {Is} {Not} {Enough}: {The} {Need} for {Consistency} in {Object} {Detection}},
	doi = {10.1109/MMUL.2022.3175239},
	journal = {IEEE MultiMedia},
	author = {Tung, Caleb and Goel, Abhinav and Bordwell, Fischer and Eliopoulos, Nick John and Hu, Xiao and Thiruvathukal, George K and Lu, Yung-Hsiang},
	year = {2022},
	pages = {1--1},
}

@article{goel_tree-based_2022,
	title = {Tree-based {Unidirectional} {Neural} {Networks} for {Low}-{Power} {Computer} {Vision}},
	url = {https://ecommons.luc.edu/cs_facpubs/317/},
	doi = {10.1109/MDAT.2022.3217016},
	journal = {IEEE Design and Test},
	author = {Goel, Abhinav and Tung, Caleb and Eliopoulos, Nick and Wang, Amy and Davis, James C. and Thiruvathukal, George K. and Lu, Yung-Hsiang},
	year = {2022},
	pages = {1--1},
}

@article{thiruvathukal_efficient_2022,
	title = {Efficient {Computer} {Vision} for {Embedded} {Systems}},
	volume = {55},
	doi = {10.1109/MC.2022.3145677},
	number = {4},
	journal = {Computer},
	author = {Thiruvathukal, George K. and Lu, Yung-Hsiang},
	year = {2022},
	pages = {15--19},
}

@article{lu_see_2019,
	title = {See the {World} {Through} {Network} {Cameras}},
	volume = {52},
	issn = {1558-0814},
	url = {https://ecommons.luc.edu/cs_facpubs/215/},
	doi = {10.1109/MC.2019.2906841},
	abstract = {Millions of network cameras have been deployed worldwide. Real-time data from many network cameras can offer instant views of multiple locations for many applications. We describe the real-time data available from these cameras and potential applications.},
	number = {10},
	journal = {Computer},
	author = {Lu, Y. and Thiruvathukal, G. K. and Kaseb, A. S. and Gauen, K. and Rijhwani, D. and Dailey, R. and Malik, D. and Huang, Y. and Aghajanzadeh, S. and Guo, M. M.},
	month = oct,
	year = {2019},
	keywords = {Visualization, Internet, Streaming media, Real-time systems, IP networks, Cameras, cameras, network cameras, Urban areas},
	pages = {30--40},
}

@article{kapach_cloud_2019,
	title = {Cloud {Resource} {Optimization} for {Processing} {Multiple} {Streams} of {Visual} {Data}},
	volume = {26},
	issn = {1941-0166},
	url = {http://ecommons.luc.edu/cs_facpubs/208},
	doi = {10.1109/MMUL.2018.2890255},
	abstract = {Hundreds of millions of network cameras have been installed throughout the world. Each is capable of providing a vast amount of real-time data. Analyzing the massive data generated by these cameras requires significant computational resources and the demands may vary over time. Cloud computing shows the most promise to provide the needed resources on demand. In this paper, we investigate how to allocate cloud resources when analyzing real-time data streams from network cameras. A resource manager considers many factors that affect its decisions, including the types of analysis, the number of data streams, and the locations of the cameras. The manager then selects the most cost-efficient types of cloud instances (e.g., central processing unit versus general-purpose graphics processing units) to meet the computational demands for analyzing streams. We evaluate the effectiveness of our approach using Amazon Web Services. Experiments demonstrate more than 50\% cost reduction for real workloads.},
	number = {3},
	journal = {IEEE MultiMedia},
	author = {Kapach, Z. and Ulmer, A. and Merrick, D. and Alikhan, A. and Lu, Y. and Mohan, A. and Kaseb, A. S. and Thiruvathukal, G. K.},
	month = jul,
	year = {2019},
	pages = {31--41},
}

@article{sullivan_former_2018,
	title = {Former {CiSE} {EICs} {Reflect} on the {Magazines} 20th {Anniversary}},
	volume = {20},
	issn = {1558-366X},
	url = {https://ecommons.luc.edu/cs_facpubs/191/},
	doi = {10.1109/MCSE.2018.011111118},
	abstract = {Former CiSE EICs reflect on the magazine’s 20th anniversary.},
	number = {1},
	journal = {Computing in Science Engineering},
	author = {Sullivan, Francis and Chonacky, Norman and Beichl, Isabel and Thiruvathukal, George K.},
	month = jan,
	year = {2018},
	pages = {3--7},
}

@article{barba_reproducible_2017,
	title = {Reproducible {Research} for {Computing} in {Science} \& {Engineering}},
	volume = {19},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {1521-9615},
	url = {https://ecommons.luc.edu/cs_facpubs/188/},
	number = {6},
	journal = {Computing in Science and Engineering},
	author = {Barba, Lorena A. and Thiruvathukal, George K.},
	year = {2017},
	pages = {85--87},
}

@article{hurlburt_graph_2017,
	title = {The {Graph} {Database}: {Jack} of {All} {Trades} or {Just} {Not} {SQL}?},
	volume = {19},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {1520-9202},
	shorttitle = {The {Graph} {Database}},
	url = {https://ecommons.luc.edu/cs_facpubs/187/},
	number = {6},
	journal = {IT Professional},
	author = {Hurlburt, George F. and Thiruvathukal, George K. and Lee, Maria R.},
	year = {2017},
	pages = {21--25},
}

@article{barnes_need_2016,
	title = {The {Need} for {Research} in {Broadening} {Participation}},
	volume = {59},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {0001-0782},
	url = {https://ecommons.luc.edu/cs_facpubs/129/},
	number = {3},
	journal = {Communications of the ACM},
	author = {Barnes, Tiffany and Thiruvathukal, George K.},
	year = {2016},
	pages = {33--34},
}

@article{barnes_best_2016,
	title = {Best of {RESPECT}, {Part} 2},
	volume = {18},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {1521-9615},
	url = {https://ecommons.luc.edu/cs_facpubs/125/},
	number = {3},
	journal = {Computing in Science and Engineering},
	author = {Barnes, Tiffany and Payton, Jamie and Thiruvathukal, George K. and Boyer, Kristy Elizabeth and Forbes, Jeffrey},
	year = {2016},
	pages = {11--13},
}

@article{thiruvathukal_how_2016,
	title = {How {AI} {Is} {Bringing} {Hollywood} to {Life}},
	url = {https://ecommons.luc.edu/cs_facpubs/120/},
	abstract = {As sci-fi readers and film buffs know, many of these ideas that have been foreshadowed–and that seem far-fetched in–fiction are beginning to seem possible. Whether we are considering the benevolent Commander Data in Star Trek: The Next Generation or fearing the terrifying Terminator, we are entering an era where AI as is rapidly entering the public discourse.},
	journal = {VentureBeat},
	author = {Thiruvathukal, George K.},
	year = {2016},
}

@article{thiruvathukal_fin_2016,
	title = {El {Fin}},
	volume = {18},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {1521-9615},
	url = {https://ecommons.luc.edu/cs_facpubs/123/},
	number = {6},
	journal = {Computing in Science and Engineering},
	author = {Thiruvathukal, George K.},
	year = {2016},
	pages = {4--6},
}

@article{thiruvathukal_beyond_2016,
	title = {Beyond {Pythagoras}},
	url = {https://ecommons.luc.edu/cs_facpubs/121/},
	journal = {EdTech Digest},
	author = {Thiruvathukal, George K.},
	year = {2016},
}

@article{thiruvathukal_next_2015,
	title = {The {Next} {Generation} of {Computational} {Science} and {Engineering}},
	volume = {17},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {1521-9615},
	url = {https://ecommons.luc.edu/cs_facpubs/258/},
	doi = {10.1109/MCSE.2015.26},
	number = {1},
	journal = {Computing in Science and Engineering},
	author = {Thiruvathukal, George K.},
	year = {2015},
	pages = {4--5},
}

@article{thiruvathukal_cloudy_2015,
	title = {Cloudy with a {Chance} of {Sunshine}, or the {Future} of {Magazine} {Publishing} ({Article}, 2015) [{WorldCat}.{Org}]},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	url = {https://ecommons.luc.edu/cs_facpubs/124/},
	journal = {Computing in Science and Engineering},
	author = {Thiruvathukal, George K.},
	year = {2015},
}

@article{thiruvathukal_all-digital_2015,
	title = {The {All}-{Digital} {Future} and {Digital} {CiSE}},
	volume = {17},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {1521-9615},
	url = {https://ecommons.luc.edu/cs_facpubs/260/},
	number = {3},
	journal = {Computing in Science and Engineering},
	author = {Thiruvathukal, George K.},
	year = {2015},
	pages = {4--5},
}

@article{terrel_scientific_2015,
	title = {Scientific {Software} {Communities}},
	volume = {17},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {1521-9615},
	url = {https://ecommons.luc.edu/cs_facpubs/262/},
	number = {1},
	journal = {Computing in Science and Engineering},
	author = {Terrel, Andy and Tobis, Michael and Thiruvathukal, George K.},
	year = {2015},
	pages = {8--10},
}

@article{parashar_extreme_2014,
	title = {Extreme {Data} [{Guest} {Editors}' {Introduction}]},
	volume = {16},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {1521-9615},
	url = {https://ecommons.luc.edu/cs_facpubs/131/},
	number = {4},
	journal = {Computing in Science and Engineering},
	author = {Parashar, Manish and Thiruvathukal, George K.},
	year = {2014},
	pages = {8--10},
}

@article{thiruvathukal_what_2014,
	title = {What {We} {Publish} in {CiSE}},
	volume = {16},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {1521-9615},
	url = {https://ecommons.luc.edu/cs_facpubs/132/},
	number = {2},
	journal = {Computing in Science and Engineering},
	author = {Thiruvathukal, George K.},
	year = {2014},
	pages = {4--6},
}

@article{thiruvathukal_who_2013,
	title = {Who {Needs} {Tablets}? {We} {Do}},
	volume = {15},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {1521-9615},
	shorttitle = {Who {Needs} {Tablets}?},
	url = {https://ecommons.luc.edu/cs_facpubs/134/},
	number = {1},
	journal = {Computing in Science and Engineering},
	author = {Thiruvathukal, George K.},
	year = {2013},
	pages = {4--6},
}

@article{thiruvathukal_whats_2013,
	title = {What's in an {Algorithm}?},
	volume = {15},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {1521-9615},
	url = {https://ecommons.luc.edu/cs_facpubs/130/},
	number = {4},
	journal = {Computing in Science and Engineering},
	author = {Thiruvathukal, George K.},
	year = {2013},
	pages = {4--5},
}

@article{thiruvathukal_productivity_2013,
	title = {Productivity in the {Cognitive} {Overload} {Era}},
	volume = {15},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {1521-9615},
	url = {https://ecommons.luc.edu/cs_facpubs/136/},
	number = {3},
	journal = {Computing in Science and Engineering},
	author = {Thiruvathukal, George K.},
	year = {2013},
	pages = {4--5},
}

@article{thiruvathukal_computational_2013,
	title = {Computational {Science}, {Demystified} - the {Future}, {Revealed} and {CiSE}, 2013},
	volume = {15},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {1521-9615},
	url = {https://ecommons.luc.edu/cs_facpubs/135/},
	number = {2},
	journal = {Computing in Science and Engineering},
	author = {Thiruvathukal, George K.},
	year = {2013},
	pages = {4--5},
}

@article{thiruvathukal_cloud_2013,
	title = {Cloud {Computing} [{Guest} {Editors}' {Introduction}]},
	volume = {15},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {1521-9615},
	url = {https://ecommons.luc.edu/cs_facpubs/131/},
	number = {4},
	journal = {Computing in Science and Engineering},
	author = {Thiruvathukal, George K. and Parashar, Manish},
	year = {2013},
	pages = {8--9},
}

@article{thiruvathukal_digging_2012,
	title = {Digging into {Data}},
	volume = {14},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {1521-9615},
	url = {https://ecommons.luc.edu/cs_facpubs/265/},
	number = {2},
	journal = {Computing in Science and Engineering},
	author = {Thiruvathukal, George K.},
	year = {2012},
	pages = {4--5},
}

@article{thiruvathukal_accelerating_2012,
	title = {Accelerating {Learning} with {Distance} {Education} and {Open} {Courseware}},
	volume = {14},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {1521-9615},
	url = {https://ecommons.luc.edu/cs_facpubs/259/},
	number = {4},
	journal = {Computing in Science and Engineering},
	author = {Thiruvathukal, George K.},
	year = {2012},
	pages = {4--5},
}

@article{milojicic_innovation_2012,
	title = {Innovation {Mashups}: {Academic} {Rigor} {Meets} {Social} {Networking} {Buzz}},
	volume = {45},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {0018-9162},
	shorttitle = {Innovation {Mashups}},
	url = {https://ecommons.luc.edu/cs_facpubs/72/},
	number = {9},
	journal = {Computer},
	author = {Milojicic, Dejan and Arlitt, Martin and Seligmann, Doree D. and Thiruvathukal, George K. and Timmerer, Christian},
	year = {2012},
	pages = {101--105},
}

@article{laufer_moving_2011,
	title = {Moving {Academic} {Department} {Functions} to {Social} {Networks} and {Clouds}: {Initial} {Experiences}},
	volume = {13},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {1521-9615},
	shorttitle = {Moving {Academic} {Department} {Functions} to {Social} {Networks} and {Clouds}},
	url = {https://ecommons.luc.edu/cs_facpubs/144/},
	number = {5},
	journal = {Computing in Science and Engineering},
	author = {Läufer, Konstantin and Thiruvathukal, George K. and Dennis, David B.},
	year = {2011},
	pages = {84--89},
}

@article{thiruvathukal_books_2011,
	title = {Books [reviews of "{Networks}, {Crowds}, and {Markets}: {Reasoning} about a {Highly}-{Connected} {World}; {Easley}, {D}. and {Kleinberg}, {J}.; 2010 and "{Introduction} to {High} {Performance} {Computing} for {Scientists} and {Engineers}"; {Hager}, {G}. and {Wellein}, {G}.; 2011)]},
	volume = {13},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {1521-9615},
	shorttitle = {Book {Review}: {Networks}, {Crowds}, and {Markets}},
	url = {https://ecommons.luc.edu/cs_facpubs/264/},
	abstract = {Two books are reviewed in this issue.},
	number = {1},
	journal = {Computing in Science and Engineering},
	author = {Thiruvathukal, George K.},
	year = {2011},
	pages = {5--8},
}

@article{thiruvathukal_beyond_2011,
	title = {Beyond {CiSE} and {Back} to the {Future}},
	volume = {13},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {1521-9615},
	url = {https://ecommons.luc.edu/cs_facpubs/18/},
	number = {3},
	journal = {Computing in Science and Engineering},
	author = {Thiruvathukal, George K.},
	year = {2011},
	pages = {4--5},
}

@article{thiruvathukal_your_2010,
	title = {Your {Local} {Cloud}-{Enabled} {Library}},
	volume = {12},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {1521-9615},
	url = {https://ecommons.luc.edu/cs_facpubs/17/},
	number = {4},
	journal = {Computing in Science and Engineering},
	author = {Thiruvathukal, George K.},
	year = {2010},
	pages = {5--6},
}

@article{thiruvathukal_virtualization_2010,
	title = {Virtualization for {Computational} {Scientists}},
	volume = {12},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {1521-9615},
	url = {https://ecommons.luc.edu/cs_facpubs/16/},
	number = {4},
	journal = {Computing in Science and Engineering},
	author = {Thiruvathukal, George K. and Läufer, Konstantin and Hinsen, Konrad and Kaylor, Joe P.},
	year = {2010},
	pages = {52--61},
}

@inproceedings{miller_toward_2020,
	title = {Toward a containerized pipeline for longitudinal analysis of open-source software projects},
	url = {http://ecommons.luc.edu/grs/2020/posters/4},
	abstract = {Trust in open-source software is a cornerstone of scientific progress and a foundation of high-quality public services. Just as standards are integral when judging the efficacy of a novel pharmaceutical compound or determining the spread of a new disease, the software used to make those determinations should be useful, error-free, reliable, performant, and secure. A small bug in an application, library, or framework can lead to economic loss and even loss of life. We rely on software developers to be dynamic and responsive to user review and bug-reporting. Our team developed an open-source modular pipeline to perform empirical investigations of software quality. A key innovation of our approach is to look at projects “from a distance” similar to methods used in climate, e.g. satellite images being used to observe environmental impacts in air quality/rain forests. Instead of looking at language-specific source code features, our pipeline uses a language-agnostic high-level approach to track software quality by focusing on the development process itself, which yields great insight into the processes programmers use to write and maintain their software. Our distributed modular approach to analytics allows the pipeline to be easily extended to support additional metrics in future work. We store extracted data in an embedded SQLite database, which means that analysis can proceed without complex server setup, let alone hosting the software on dedicated servers. Our analytical modules are designed for efficiency, and future runs of our software only collect missing data, supporting the incremental analysis of known, important open-source projects.},
	booktitle = {Graduate {Research} {Symposium} 2020},
	author = {Miller, Allan and Thiruvathukal, George K. and Läufer, Konstantin and Amobi, Emmanuel and Higgins, Sean and Maliakal, Linette and Meister, Emily and Putter, Jean-Luc and Rose, Alex and Synovic, Nicholas and Von Hatten, Sophie and Warkentin, Jonathan and Zugschwert, Martin},
	year = {2020},
}

@misc{caughie_woolf_2018,
	title = {Woolf {Online}},
	url = {http://woolfonline.com},
	author = {Caughie, Pamela L. and Hayward, Nicholas J. and Hussey, Mark and Shillingsburg, Peter J. and Thiruvathukal, George K.},
	year = {2018},
}

@misc{brophy_quantitative_2015,
	title = {Quantitative {Morphological} {Analysis} of {Bovid} {Teeth} {Using} {Elliptical} {Fourier} {Function} {Analyses}},
	author = {Brophy, Juliet K. and Matthews, Gregory J. and Thiruvathukal, George K.},
	year = {2015},
	note = {Place: UCLA},
}

@misc{thiruvathukal_gcasr_2015,
	title = {{GCASR} 15: {Middleware} for {Collaborative} {Distributed}/{Mobile} {Applications}: {XMPP} or {Reactive} {HTTP}?},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	shorttitle = {{GCASR} 15},
	author = {Thiruvathukal, George K.},
	year = {2015},
}

@misc{putonti_organised_2015,
	title = {Organised {Genomic} {HIV} and {Pseudomonas} {Sequence} {Data}},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	url = {https://figshare.com/articles/dataset/hivdb/1564844},
	publisher = {Figshare},
	author = {Putonti, Catherine and Thiruvathukal, George K.},
	month = oct,
	year = {2015},
	doi = {10.6084/m9.figshare.1564844.v3},
}

@inproceedings{lewis_scala_2014,
	address = {ACM, 2 Penn Plaza, Suite 701, New York, NY 10121-0701, USA},
	title = {Scala for {Introductory} {CS} and {Parallelism} ({Workshop})},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	isbn = {978-1-4503-2605-6},
	url = {https://scalaworkshop.cs.luc.edu},
	abstract = {Scala is one of a new breed of hybrid languages with both object-oriented and functional aspects. It happens to be the most successful of these languages coming in at \#12 on the Red Monk language ranking and leading all languages in their 2nd tier. This workshop will introduce participants to the Scala programming language, how it can be used effectively in introductory CS courses, and the parallel tools that are available for it. We begin with simple examples in the REPL and scripting environment, then look at doing larger, object-oriented projects. We finish off with an exploration of composable futures and the Akka actor library. Participants are strongly recommended to bring a laptop.},
	booktitle = {45th {ACM} technical symposium / {Computer} science education ({SIGCSE} '14)},
	author = {Lewis, Mark and Läufer, Konstantin and Thiruvathukal, George K.},
	year = {2014},
}

@misc{dias_building_2013,
	title = {Building {Capable}, {Energy}-{Efficient}, {Flexible} {Visualization} and {Sensing} {Clusters} from {Commodity} {Tablets}},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	shorttitle = {{GCASR} 15},
	url = {https://ecommons.luc.edu/cs_facpubs/66/},
	author = {Dias, Thomas Delgado and Yan, Xian and Läufer, Konstantin and Thiruvathukal, George K.},
	year = {2013},
}

@misc{stasiuk_network_2013,
	title = {Network {Technologies} {Used} to {Aggregate} {Environmental} {Data}},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	shorttitle = {{GCASR} 13},
	url = {https://ecommons.luc.edu/cs_facpubs/65/},
	author = {Stasiuk, Paul and Läufer, Konstantin and Thiruvathukal, George K.},
	year = {2013},
}

@inproceedings{lewis_using_2013,
	address = {ACM, 2 Penn Plaza, Suite 701, New York, NY 10121-0701, USA},
	title = {Using {Scala} strategically across the undergraduate curriculum (abstract only)},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	isbn = {978-1-4503-1868-6},
	url = {https://ecommons.luc.edu/cs_facpubs/69/},
	abstract = {Various hybrid-paradigm languages, designed to balance compile-time error detection, conciseness, and performance, have emerged. Scala, e.g., is interoperable with Java and has become an early leader in adoption, especially in the start-up and open-source spaces. Workshop participants experience Scala's value as a teaching language in the CS curriculum through four lecture-lab modules: In CS1, the read-eval-print loop and simple, uniform syntax aid programming in the small. In CS2, higher-order methods allow concise, efficient manipulation of collections. Advanced topics include domain-specific languages, concurrency, web apps/services, and mobile apps. Laptop recommended with Scala installed.},
	booktitle = {44th {ACM} technical symposium / {Computer} science education ({SIGCSE} '13)},
	author = {Lewis, Mark and Läufer, Konstantin and Thiruvathukal, George K.},
	year = {2013},
}

@inproceedings{veselsky_establishing_2022,
	address = {New York, NY, USA},
	series = {{HotMobile} '22},
	title = {Establishing {Trust} in {Vehicle}-to-{Vehicle} {Coordination}: {A} {Sensor} {Fusion} {Approach}},
	isbn = {978-1-4503-9218-1},
	url = {https://doi.org/10.1145/3508396.3517075},
	doi = {10.1145/3508396.3517075},
	abstract = {As we add more autonomous and semi-autonomous vehicles (AVs) to our roads, their effects on passenger and pedestrian safety are becoming more important. Despite extensive testing before deployment, AV systems are not perfect at identifying hazards in the roadway. Although a particular AV’s sensors and software may not be 100 percent accurate at identifying hazards, there is an untapped pool of information held by other AVs in the vicinity that could be used to quickly and accurately identify roadway hazards before they present a safety threat.},
	booktitle = {Proceedings of the 23rd {Annual} {International} {Workshop} on {Mobile} {Computing} {Systems} and {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Veselsky, Jakob and West, Jack and Ahlgren, Isaac and Thiruvathukal, George K. and Klingensmith, Neil and Goel, Abhinav and Jiang, Wenxin and Davis, James C. and Lee, Kyuin and Kim, Younghyun},
	year = {2022},
	note = {event-place: Tempe, Arizona},
	pages = {128},
}

@inproceedings{veselsky_establishing_2022-1,
	address = {New York, NY, USA},
	series = {{HotMobile} '22},
	title = {Establishing {Trust} in {Vehicle}-to-{Vehicle} {Coordination}: {A} {Sensor} {Fusion} {Approach}},
	isbn = {978-1-4503-9218-1},
	url = {https://doi.org/10.1145/3508396.3517075},
	doi = {10.1145/3508396.3517075},
	abstract = {As we add more autonomous and semi-autonomous vehicles (AVs) to our roads, their effects on passenger and pedestrian safety are becoming more important. Despite extensive testing before deployment, AV systems are not perfect at identifying hazards in the roadway. Although a particular AV’s sensors and software may not be 100\% accurate at identifying hazards, there is an untapped pool of information held by other AVs in the vicinity that could be used to quickly and accurately identify roadway hazards before they present a safety threat.},
	booktitle = {Proceedings of the 23rd {Annual} {International} {Workshop} on {Mobile} {Computing} {Systems} and {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Veselsky, Jakob and West, Jack and Ahlgren, Isaac and Thiruvathukal, George K. and Klingensmith, Neil and Goel, Abhinav and Jiang, Wenxin and Davis, James C. and Lee, Kyuin and Kim, Younghyun},
	year = {2022},
	note = {event-place: Tempe, Arizona},
	pages = {128},
}

@misc{banna_experience_2021,
	title = {An {Experience} {Report} on {Machine} {Learning} {Reproducibility}: {Guidance} for {Practitioners} and {TensorFlow} {Model} {Garden} {Contributors}},
	abstract = {Machine learning techniques are becoming a fundamental tool for scientific and engineering progress. These techniques are applied in contexts as diverse as astronomy and spam filtering. However, correctly applying these techniques requires careful engineering. Much attention has been paid to the technical potential; relatively little attention has been paid to the software engineering process required to bring research-based machine learning techniques into practical utility. Technology companies have supported the engineering community through machine learning frameworks such as TensorFLow and PyTorch, but the details of how to engineer complex machine learning models in these frameworks have remained hidden. To promote best practices within the engineering community, academic institutions and Google have partnered to launch a Special Interest Group on Machine Learning Models (SIGMODELS) whose goal is to develop exemplary implementations of prominent machine learning models in community locations such as the TensorFlow Model Garden (TFMG). The purpose of this report is to define a process for reproducing a state-of-the-art machine learning model at a level of quality suitable for inclusion in the TFMG. We define the engineering process and elaborate on each step, from paper analysis to model release. We report on our experiences implementing the YOLO model family with a team of 26 student researchers, share the tools we developed, and describe the lessons we learned along the way.},
	author = {Banna, Vishnu and Chinnakotla, Akhil and Yan, Zhengxin and Vegesana, Ani and Vivek, Naveen and Krishnappa, Kruthi and Jiang, Wenxin and Lu, Yung-Hsiang and Thiruvathukal, George K. and Davis, James C.},
	year = {2021},
	note = {\_eprint: 2107.00821},
}

@misc{west_voltkey_2020,
	title = {{VoltKey}: {Using} {Power} {Line} {Noise} for {Zero}-{Involvement} {Pairing} and {Authentication} ({Demo} {Abstract})},
	author = {West, Jack and VoNguyen, Tien and Ahlgren, Isaac and Motyashok, Iryna and Thiruvathukal, George K. and Klingensmith, Neil},
	year = {2020},
	note = {\_eprint: 2004.00092},
}

@misc{ghodgaonkar_observing_2020,
	title = {Observing {Responses} to the {COVID}-19 {Pandemic} using {Worldwide} {Network} {Cameras}},
	abstract = {COVID-19 has resulted in a worldwide pandemic, leading to "lockdown" policies and social distancing. The pandemic has profoundly changed the world. Traditional methods for observing these historical events are difficult because sending reporters to areas with many infected people can put the reporters' lives in danger. New technologies are needed for safely observing responses to these policies. This paper reports using thousands of network cameras deployed worldwide for the purpose of witnessing activities in response to the policies. The network cameras can continuously provide real-time visual data (image and video) without human efforts. Thus, network cameras can be utilized to observe activities without risking the lives of reporters. This paper describes a project that uses network cameras to observe responses to governments' policies during the COVID-19 pandemic (March to April in 2020). The project discovers over 30,000 network cameras deployed in 110 countries. A set of computer tools are created to collect visual data from network cameras continuously during the pandemic. This paper describes the methods to discover network cameras on the Internet, the methods to collect and manage data, and preliminary results of data analysis. This project can be the foundation for observing the possible "second wave" in fall 2020. The data may be used for post-pandemic analysis by sociologists, public health experts, and meteorologists.},
	author = {Ghodgaonkar, Isha and Goel, Abhinav and Bordwell, Fischer and Tung, Caleb and Aghajanzadeh, Sara and Curran, Noah and Chen, Ryan and Yu, Kaiwen and Mahapatra, Sneha and Banna, Vishnu and Kao, Gore and Lee, Kate and Hu, Xiao and Eliopolous, Nick and Chinnakotla, Akhil and Rijhwani, Damini and Kim, Ashley and Chakraborty, Aditya and Ward, Mark Daniel and Lu, Yung-Hsiang and Thiruvathukal, George K.},
	year = {2020},
	note = {\_eprint: 2005.09091},
}

@misc{thiruvathukal_benchmarking_2019,
	title = {A {Benchmarking} {Study} to {Evaluate} {Apache} {Spark} on {Large}-{Scale} {Supercomputers}},
	author = {Thiruvathukal, George K. and Christensen, Cameron and Jin, Xiaoyong and Tessier, François and Vishwanath, Venkatram},
	year = {2019},
	note = {\_eprint: 1904.11812},
}

@article{smith_siam_2019,
	title = {{SIAM} {CSE} 2019 {Minisymposterium}: {The} {Journal} of {Open} {Source} {Software}},
	url = {https://figshare.com/articles/poster/SIAM_CSE_2019_Minisymposterium_The_Journal_of_Open_Source_Software/7763171},
	doi = {10.6084/m9.figshare.7763171.v1},
	author = {Smith, Arfon and Barba, Lorena A. and Katz, Daniel S. and Niemeyer, Kyle and Allard, Tania and Bazan, Juanjo and Brown, Jed and Clark, Jason and Guimera, Roman Valls and Gymrek, Melissa and Heagy, Lindsey and Huff, Kathryn and Thiruvathukal, George K. and Madan, Christopher and Moerman, Kevin and Pantano, Lorena and Pons, Viviane and Poulson, Jack and Prins, Pjotr and Ram, Karthik and Ramirez, Elizabeth and Rokem, Ariel and Thyng, Kristen and Yehudi, Yo},
	month = feb,
	year = {2019},
}

@techreport{carver_collaborative_2016,
	title = {Collaborative {Research}: {Making} {Software} {Engineering} {Work} for {Computational} {Science} \& {Engineering}: {An} {Integrated} {Approach}},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	shorttitle = {Collaborative {Research}},
	institution = {Figshare},
	author = {Carver, Jeffrey C. and Thiruvathukal, George K.},
	year = {2016},
}

@techreport{thiruvathukal_apt_2015,
	title = {Apt {Compiler} {Toolkit} ({Legacy} {Document})},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	institution = {Figshare},
	author = {Thiruvathukal, George K. and Verun, Ufuk},
	year = {2015},
}
